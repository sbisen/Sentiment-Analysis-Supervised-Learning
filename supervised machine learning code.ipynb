{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>our_id</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>sentiment_gold_reason</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>724227031</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>10001</td>\n",
       "      <td>5\\n4</td>\n",
       "      <td>Author is excited about the development of the...</td>\n",
       "      <td>Two places I'd invest all my money if I could:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>724227032</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8775</td>\n",
       "      <td>10002</td>\n",
       "      <td>5\\n4</td>\n",
       "      <td>Author is excited that driverless cars will be...</td>\n",
       "      <td>Awesome! Google driverless cars will help the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>724227033</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>10003</td>\n",
       "      <td>2\\n1</td>\n",
       "      <td>The author is skeptical of the safety and reli...</td>\n",
       "      <td>If Google maps can't keep up with road constru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>724227034</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>10004</td>\n",
       "      <td>2\\n1</td>\n",
       "      <td>The author is skeptical of the project's value.</td>\n",
       "      <td>Autonomous cars seem way overhyped given the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>724227035</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10005</td>\n",
       "      <td>3</td>\n",
       "      <td>Author is making an observation without expres...</td>\n",
       "      <td>Just saw Google self-driving car on I-34. It w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  724227031     True      golden                 236               NaN   \n",
       "1  724227032     True      golden                 231               NaN   \n",
       "2  724227033     True      golden                 233               NaN   \n",
       "3  724227034     True      golden                 240               NaN   \n",
       "4  724227035     True      golden                 240               NaN   \n",
       "\n",
       "  sentiment  sentiment:confidence  our_id sentiment_gold  \\\n",
       "0         5                0.7579   10001           5\\n4   \n",
       "1         5                0.8775   10002           5\\n4   \n",
       "2         2                0.6805   10003           2\\n1   \n",
       "3         2                0.8820   10004           2\\n1   \n",
       "4         3                1.0000   10005              3   \n",
       "\n",
       "                               sentiment_gold_reason  \\\n",
       "0  Author is excited about the development of the...   \n",
       "1  Author is excited that driverless cars will be...   \n",
       "2  The author is skeptical of the safety and reli...   \n",
       "3    The author is skeptical of the project's value.   \n",
       "4  Author is making an observation without expres...   \n",
       "\n",
       "                                                text  \n",
       "0  Two places I'd invest all my money if I could:...  \n",
       "1  Awesome! Google driverless cars will help the ...  \n",
       "2  If Google maps can't keep up with road constru...  \n",
       "3  Autonomous cars seem way overhyped given the t...  \n",
       "4  Just saw Google self-driving car on I-34. It w...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Step 1 Reading the training dataset\n",
    "train = pd.read_csv(\"Twitter-sentiment-self-drive-DFE.csv\")\n",
    "\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     places invest money could printing self drivin...\n",
       "1     awesome google driverless cars will help blind...\n",
       "2     google maps keep with road construction suppos...\n",
       "3     autonomous cars seem overhyped given technolog...\n",
       "4           just google self driving painted green blue\n",
       "5     will driverless cars eventually replace taxi d...\n",
       "6          chicago metro expected fully autonomous 2020\n",
       "7     love infotainment system this thing almost dri...\n",
       "8     autonomous vehicles could reduce traffic fatal...\n",
       "9     driverless cars worth risk want highway when s...\n",
       "10    driverless cars legal florida california michigan\n",
       "11    audi first carmaker license from nevada test a...\n",
       "12    audi says first manufacturer world license fro...\n",
       "13    future buying these audi ready test autonomous...\n",
       "14    audi test driving their driverless tampa today...\n",
       "15    audi first automaker california test self driv...\n",
       "16    audi gets first permit test self driving cars ...\n",
       "17    audi gets permit test self driving cars califo...\n",
       "18    google audi mercedes california first self dri...\n",
       "19    audi gets first permit test driverless cars ca...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "#Step 2= Removing Twitter Handles\n",
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt \n",
    "\n",
    "# creating new column tidy_tweet & remove twitter handles (@user)\n",
    "train['clean_text'] = np.vectorize(remove_pattern)(train['text'], \"@[\\w]*\")\n",
    "\n",
    "train['clean_text'] = train['clean_text'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "\n",
    "#Step 3= Removing Punctuations, Numbers, and Special Character \n",
    "train['clean_text'] = train['clean_text'].str.replace('[^A-Za-z0-9]+', ' ')\n",
    "                          \n",
    "# Step 4 remove stopwords\n",
    "train['clean_text'] = train['clean_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "\n",
    "#Step 5 to lowercase\n",
    "\n",
    "train['clean_text']= train['clean_text'].apply(lambda x: ''.join([w for w in x.lower()]))\n",
    "\n",
    "train['clean_text'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train['clean_text'], train['sentiment'],test_size = 0.2)\n",
    "\n",
    "## for transforming the 80% of the train data ##\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(norm='l2',sublinear_tf=True)\n",
    "x_train_tfidf = transformer.fit_transform(x_train_counts)\n",
    "x_train_tfidf.shape\n",
    "\n",
    "## for transforming the 20% of the train data which is being used for validation ##\n",
    "x_test_counts = count_vect.transform(x_test)\n",
    "x_test_tfidf = transformer.transform(x_test_counts)\n",
    "\n",
    "\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=980) \n",
    "model= model.fit(x_train_tfidf,y_train)\n",
    "\n",
    "prediction = model.predict(x_test_tfidf)\n",
    "#print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6243016759776536\n"
     ]
    }
   ],
   "source": [
    "# testing model's accuracy with accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.score(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2052355977733853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_score = cohen_kappa_score(y_test, prediction)\n",
    "print(cohen_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[  0   3  17   3   0   0]\n",
      " [  0  11 148   8   0   0]\n",
      " [  0   3 802  29   5   0]\n",
      " [  0   0 193  72  12   0]\n",
      " [  0   0  45  46   7   0]\n",
      " [  0   0  25   1   0   2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.65      0.07      0.12       167\n",
      "           3       0.65      0.96      0.78       839\n",
      "           4       0.45      0.26      0.33       277\n",
      "           5       0.29      0.07      0.11        98\n",
      "not_relevant       1.00      0.07      0.13        28\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      1432\n",
      "   macro avg       0.51      0.24      0.25      1432\n",
      "weighted avg       0.58      0.62      0.54      1432\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# creates a ML model based on parameters\n",
    "model2 = MultinomialNB()\n",
    "model2 = model2.fit(x_train_tfidf,y_train)\n",
    "prediction2 = model2.predict(x_test_tfidf)\n",
    "#print(prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5879888268156425\n"
     ]
    }
   ],
   "source": [
    "# testing model's accuracy with accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,prediction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018056382029157936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_score = cohen_kappa_score(y_test, prediction2)\n",
    "print(cohen_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.score(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[  0   0  23   0   0   0]\n",
      " [  0   0 167   0   0   0]\n",
      " [  0   0 834   5   0   0]\n",
      " [  0   0 269   8   0   0]\n",
      " [  0   0  91   7   0   0]\n",
      " [  0   0  28   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test, prediction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.00      0.00      0.00       167\n",
      "           3       0.59      0.99      0.74       839\n",
      "           4       0.40      0.03      0.05       277\n",
      "           5       0.00      0.00      0.00        98\n",
      "not_relevant       0.00      0.00      0.00        28\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      1432\n",
      "   macro avg       0.17      0.17      0.13      1432\n",
      "weighted avg       0.42      0.59      0.44      1432\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, prediction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(x_train_tfidf,y_train)\n",
    "prediction3 = log_model.predict(x_test_tfidf)\n",
    "\n",
    "#print(prediction3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6138268156424581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, prediction3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14792446089998312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_score = cohen_kappa_score(y_test, prediction3)\n",
    "print(cohen_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_model.score(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[  0   0  20   3   0   0]\n",
      " [  0   1 154  12   0   0]\n",
      " [  0   0 819  19   1   0]\n",
      " [  0   0 216  55   6   0]\n",
      " [  0   0  57  37   4   0]\n",
      " [  0   0  27   1   0   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test, prediction3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       1.00      0.01      0.01       167\n",
      "           3       0.63      0.98      0.77       839\n",
      "           4       0.43      0.20      0.27       277\n",
      "           5       0.36      0.04      0.07        98\n",
      "not_relevant       0.00      0.00      0.00        28\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      1432\n",
      "   macro avg       0.41      0.20      0.19      1432\n",
      "weighted avg       0.60      0.61      0.51      1432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, prediction3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "# creates a ML model based on parameters\n",
    "modelDTg = tree.DecisionTreeClassifier(criterion='gini') \n",
    "modelDTg = modelDTg.fit(x_train_tfidf,y_train)\n",
    "predictionDTg = modelDTg.predict(x_test_tfidf)\n",
    "#print(predictionDTg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: \n",
      " 0.5495810055865922\n",
      "confusion matrix: \n",
      " [[  0   3  15   4   1   0]\n",
      " [  2  19 111  31   2   2]\n",
      " [  2  42 667 103  15  10]\n",
      " [  1  21 148  81  24   2]\n",
      " [  0   9  32  41  15   1]\n",
      " [  0   1  20   2   0   5]]\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.20      0.11      0.15       167\n",
      "           3       0.67      0.79      0.73       839\n",
      "           4       0.31      0.29      0.30       277\n",
      "           5       0.26      0.15      0.19        98\n",
      "not_relevant       0.25      0.18      0.21        28\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      1432\n",
      "   macro avg       0.28      0.26      0.26      1432\n",
      "weighted avg       0.50      0.55      0.52      1432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score: \\n',accuracy_score(y_test, predictionDTg))\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test, predictionDTg))\n",
    "print('classification report: \\n',classification_report(y_test, predictionDTg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17737578564958745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_score = cohen_kappa_score(y_test, predictionDTg)\n",
    "print(cohen_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelDTg.score(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "# creates a ML model based on parameters\n",
    "modelDTe = tree.DecisionTreeClassifier(criterion='entropy') \n",
    "modelDTe = modelDTe.fit(x_train_tfidf,y_train)\n",
    "predictionDTe = modelDTe.predict(x_test_tfidf)\n",
    "#print(predictionDTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: \n",
      " 0.5314245810055865\n",
      "confusion matrix: \n",
      " [[  1   7  12   3   0   0]\n",
      " [  2  14 115  32   4   0]\n",
      " [  4  47 659  93  22  14]\n",
      " [  2  17 156  66  30   6]\n",
      " [  0   7  39  32  18   2]\n",
      " [  0   0  20   5   0   3]]\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.11      0.04      0.06        23\n",
      "           2       0.15      0.08      0.11       167\n",
      "           3       0.66      0.79      0.72       839\n",
      "           4       0.29      0.24      0.26       277\n",
      "           5       0.24      0.18      0.21        98\n",
      "not_relevant       0.12      0.11      0.11        28\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      1432\n",
      "   macro avg       0.26      0.24      0.24      1432\n",
      "weighted avg       0.48      0.53      0.50      1432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score: \\n',accuracy_score(y_test, predictionDTe))\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test, predictionDTe))\n",
    "print('classification report: \\n',classification_report(y_test, predictionDTe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5' '5' '4' ... '3' '3' 'not_relevant']\n",
      "accuracy score: \n",
      " 0.598463687150838\n",
      "confusion matrix: \n",
      " [[  1   3  16   3   0   0]\n",
      " [  1   9 147   9   1   0]\n",
      " [  1   7 798  29   3   1]\n",
      " [  0   2 227  38  10   0]\n",
      " [  0   0  60  27  11   0]\n",
      " [  0   2  26   0   0   0]]\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.04      0.08        23\n",
      "           2       0.39      0.05      0.09       167\n",
      "           3       0.63      0.95      0.76       839\n",
      "           4       0.36      0.14      0.20       277\n",
      "           5       0.44      0.11      0.18        98\n",
      "not_relevant       0.00      0.00      0.00        28\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      1432\n",
      "   macro avg       0.36      0.22      0.22      1432\n",
      "weighted avg       0.52      0.60      0.51      1432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-NN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn= knn.fit(x_train_tfidf,y_train)\n",
    "predictionKNN = knn.predict(x_test_tfidf)\n",
    "print(predictionDTe)\n",
    "\n",
    "print('accuracy score: \\n',accuracy_score(y_test, predictionKNN))\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test, predictionKNN))\n",
    "print('classification report: \\n',classification_report(y_test, predictionKNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1295872674917653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_score = cohen_kappa_score(y_test, predictionKNN)\n",
    "print(cohen_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn.score(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.959643605870021"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "clf = OneVsRestClassifier(svm.SVC(gamma=0.01, C=100., probability=True, class_weight='balanced', kernel='linear'))\n",
    "clf_output = clf.fit(x_train_tfidf,y_train)\n",
    "predictionSVM = clf_output.predict(x_test_tfidf)\n",
    "clf_output.score(x_train_tfidf,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(predictionSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: \n",
      " 0.5160614525139665\n",
      "confusion matrix: \n",
      " [[  1   7   5   9   0   1]\n",
      " [  7  29  75  36  12   8]\n",
      " [ 10  40 584 139  33  33]\n",
      " [  4  18 116  96  36   7]\n",
      " [  0   2  31  38  25   2]\n",
      " [  2   3  15   4   0   4]]\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.04      0.04      0.04        23\n",
      "           2       0.29      0.17      0.22       167\n",
      "           3       0.71      0.70      0.70       839\n",
      "           4       0.30      0.35      0.32       277\n",
      "           5       0.24      0.26      0.25        98\n",
      "not_relevant       0.07      0.14      0.10        28\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      1432\n",
      "   macro avg       0.27      0.28      0.27      1432\n",
      "weighted avg       0.52      0.52      0.52      1432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score: \\n',accuracy_score(y_test, predictionSVM))\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test, predictionSVM))\n",
    "print('classification report: \\n',classification_report(y_test, predictionSVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19931128131850573\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_score = cohen_kappa_score(y_test, predictionSVM)\n",
    "print(cohen_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris.data.shape, iris.target.shape\n",
    "((150, 4), (150,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "((90, 4), (90,))\n",
    "X_test.shape, y_test.shape\n",
    "((60, 4), (60,))\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.88888889, 1.        , 1.        ,\n",
       "       1.        , 0.88888889, 0.88888889, 1.        , 1.        ,\n",
       "       1.        , 0.83333333, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=20)\n",
    "scores   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
